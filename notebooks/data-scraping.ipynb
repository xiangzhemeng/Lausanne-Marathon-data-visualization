{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "% matplotlib inline\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rankings_p = '../data/rankings.p'\n",
    "headers_p = '../data/headers.p'\n",
    "\n",
    "# function to scrape marathon data\n",
    "def scrape_marathon_data():\n",
    "    years = range(2002, 2018)\n",
    "    letters = [chr(x + ord('A')) for x in range(0, 26)]\n",
    "\n",
    "    URL = \"https://services.datasport.com/{}/lauf/lamara/ALFA{}.HTM\"\n",
    "    \n",
    "    rankings = {}\n",
    "    headers = {}\n",
    "    for year in years:\n",
    "        print(str(year) + \": \", end='')\n",
    "        rankings[str(year)] = []\n",
    "        for letter in letters:\n",
    "            r = requests.get(URL.format(year, letter))\n",
    "            soup = bs(r.text, 'html.parser')\n",
    "            title = soup.find('title').getText()\n",
    "            if(title != 'Adresse nicht vorhanden / The address is not available'):\n",
    "                data = soup.findAll('font', {'size':'2'})\n",
    "\n",
    "                print(letter, end='')\n",
    "                headers[str(year)] = data[0].getText()\n",
    "                rankings[str(year)].extend(re.compile('¦ *\\r\\n').split(data[1].getText()))\n",
    "            else:\n",
    "                print(\"Skipped\")\n",
    "        print('')\n",
    "\n",
    "    # Pickle data\n",
    "    pickle.dump(rankings, open(rankings_p, 'wb'))\n",
    "    pickle.dump(headers, open(headers_p, 'wb'))\n",
    "    return rankings, headers\n",
    "\n",
    "# Only scrape if pickle unavailable\n",
    "def get_data(force_scrape=False):\n",
    "    if force_scrape:\n",
    "        print('Scrape data from website')\n",
    "        return scrape_marathon_data()\n",
    "    try:\n",
    "        print('Trying to load data from pickle')\n",
    "        return pickle.load(open(rankings_p, 'rb')), pickle.load(open(headers_p, 'rb'))\n",
    "    except (OSError, IOError) as e:\n",
    "        print('Failed to load pickle:')\n",
    "        print(e)\n",
    "        print('Scrape data from website')\n",
    "        return scrape_marathon_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function finds the position of where the pages should be split into columns\n",
    "based on whitespace\n",
    "\"\"\"\n",
    "def parse_columns(ranking, header):\n",
    "    column_structure = {}\n",
    "    column_mask = np.ones(np.array(list(ranking[0])).shape, dtype=bool)\n",
    "    spaces_mask = np.ones(np.array(list(ranking[0])).shape)*32\n",
    "    \n",
    "    # create mask of space positions for field delimiter detection\n",
    "    for line in ranking[:-1]:\n",
    "        cur_line = np.array(list(line)).view(np.uint32)\n",
    "        \n",
    "        try:\n",
    "            column_mask = np.logical_and(column_mask, np.equal(cur_line, spaces_mask))\n",
    "        except:\n",
    "            #print(\"Skipped line:\", line)\n",
    "            #print(cur_line.shape, column_mask.shape)\n",
    "            pass\n",
    "        \n",
    "    # include header in space position mask\n",
    "    header_int = np.array(list(header[:column_mask.shape[0]])).view(np.uint32)\n",
    "    column_mask = np.logical_and(column_mask, np.equal(header_int, spaces_mask))\n",
    "        \n",
    "    # find field delimiter positions\n",
    "    inside_space_col = False\n",
    "    delimiters = []\n",
    "    for i, is_space_col in enumerate(list(column_mask)):\n",
    "        if is_space_col:\n",
    "            if not inside_space_col:\n",
    "                inside_space_col = True\n",
    "                delimiters.append(i)\n",
    "                \n",
    "        elif inside_space_col:\n",
    "            inside_space_col = False\n",
    "            \n",
    "    return delimiters\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Seperates the lists of lines into columns and create a dictionary of dataframes\n",
    "\"\"\"\n",
    "def separate_cols(rankings, headers):\n",
    "    # dictionary to keep dataframes in\n",
    "    dfs = {}\n",
    "    for year in rankings:\n",
    "        ranking = rankings[year]\n",
    "        header = headers[year]\n",
    "        \n",
    "        # fix offset headers in 2007-2009 data\n",
    "        if year in ['2007', '2008', '2009']:\n",
    "            header = header.replace('an lieu', 'an   lieu')\n",
    "        delimiters = parse_columns(ranking, header)\n",
    "\n",
    "        # find positions for each field\n",
    "        start = 0\n",
    "        cols = {} \n",
    "        unnamed = 0\n",
    "        for delimiter in delimiters:\n",
    "            key = header[start:delimiter+1].strip()\n",
    "            if key == '':\n",
    "                key = unnamed\n",
    "                unnamed += 1\n",
    "            cols[key] = (start, delimiter+1)\n",
    "            start = delimiter+1\n",
    "\n",
    "        start = 0\n",
    "        result = {}\n",
    "        for i, line in enumerate(ranking):\n",
    "            if '\\r\\ntotal ' not in line and '\\r\\nTotal' not in line:\n",
    "                for col in cols:\n",
    "                    start, end = cols[col]\n",
    "                    if col in result:\n",
    "                        result[col].append(line[start:end].strip())\n",
    "                    else:\n",
    "                        result[col] = [line[start:end].strip()]\n",
    "        dfs[year] = pd.DataFrame(result, columns=result.keys()) \n",
    "    print('Columns separated')\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'lieu': '',\n",
    "    0: 'DELETE',\n",
    "    2: 'DELETE',\n",
    "    3: 'DELETE',\n",
    "    'catégorie': '',\n",
    "    'nom': '',\n",
    "    1: 'DELETE',\n",
    "    'temps': '',\n",
    "    'Jg': 'an',\n",
    "    'an lieu': '',\n",
    "    'overall': '',\n",
    "    'retard': '',\n",
    "    'équipe': '',\n",
    "    'moyenne': '',\n",
    "    'Rang': 'rang',\n",
    "    'nom/lieu': '',\n",
    "    'Stnr': 'doss',\n",
    "    'an': '',\n",
    "    'pénalité': '',\n",
    "    'doss': '',\n",
    "    'temps net': '',\n",
    "    'rang': '',\n",
    "    '¦': 'DELETE',\n",
    "    'équipe/lieu': '',\n",
    "    'Rückstand': 'retard',\n",
    "    'Kategorie': 'catégorie',\n",
    "    'Team/Ortschaft': 'équipe/lieu',\n",
    "    'Name/Ort': 'nom/lieu',\n",
    "    'Zeit': 'temps'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Where possible, this function matches the names of the columns \n",
    "of the individual dataframes\n",
    "\"\"\"\n",
    "def normalize_column_names(dfs_):\n",
    "    dfs_c = dfs_.copy()\n",
    "    for year, _ in dfs_c.items():\n",
    "        for header_name in list(dfs_c[year]):\n",
    "            if mapping[header_name] == 'DELETE':\n",
    "                dfs_c[year] = dfs_c[year].drop(header_name, axis=1)\n",
    "            elif mapping[header_name] != \"\":\n",
    "                dfs_c[year] = dfs_c[year].rename(columns = {header_name : mapping[header_name]})\n",
    "                print(\"Renamed {} to {} in year {}\".format(\n",
    "                    header_name, mapping[header_name], year))\n",
    "    print('Column names normalized')\n",
    "    return dfs_c\n",
    "                \n",
    "\n",
    "\n",
    "def print_col_overview(dfs):\n",
    "    # fields present in all years\n",
    "    shared_fields = set.intersection(*[set(v) for k, v in dfs.items()])\n",
    "    print(\"Shared fields:\", shared_fields)\n",
    "\n",
    "    fields = set()\n",
    "    for year in sorted(dfs):\n",
    "        fields = fields.union(set(list(dfs[year])))\n",
    "        print(year)\n",
    "        print(set(dfs[year]).difference(shared_fields))\n",
    "    print(\"Union remaining fields:\", fields.difference(shared_fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_cities(dfs_):\n",
    "    dfs_c = dfs_.copy()\n",
    "    \"\"\"\n",
    "    Years 2002-2006 have a team/city field and a name/city field.\n",
    "    If a team is provided, the city is added to the end of the name,\n",
    "    after a comma (',').\n",
    "    \n",
    "    This function removes the teams and converts the column 'équipe/lieu' \n",
    "    to a dedicated 'lieu' column\n",
    "    \"\"\"\n",
    "    for year, df in dfs_c.items():\n",
    "        col_name = 'nom/lieu'\n",
    "        col_team = 'équipe/lieu'\n",
    "        if col_name in df:\n",
    "            for i, row in df.iterrows():\n",
    "                m = re.compile('(.*), (.*)').match(row[col_name])\n",
    "                if m is not None:\n",
    "                    dfs_c[year].at[i, col_name] = m.group(1)\n",
    "                    dfs_c[year].at[i, col_team] = m.group(2)\n",
    "            # rename columns\n",
    "        rename_dict = {col_name : 'nom', col_team: 'lieu'}\n",
    "        dfs_c[year].rename(columns=rename_dict, inplace=True)\n",
    "    print('Cities fixed')\n",
    "    return dfs_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the fields that are present in all years\n",
    "\"\"\"\n",
    "def get_shared_fields(dfs):\n",
    "    return set.intersection(*[set(v) for k, v in dfs.items()])\n",
    "\n",
    "\"\"\"\n",
    "Returns the fields that are only present in some of the years\n",
    "\"\"\"\n",
    "def get_unshared_fields(dfs):\n",
    "    return set.union(*[set(v) for k, v in dfs.items()]).difference(get_shared_fields(dfs))\n",
    "\n",
    "\"\"\"\n",
    "Deletes columns from dataframes that are only present in some of the years\n",
    "\"\"\"\n",
    "def drop_uncommon_fields(dfs_):\n",
    "    dfs_c = dfs_.copy()\n",
    "    for year, df in dfs_c.items():\n",
    "        dfs_c[year] = dfs_c[year][list(get_shared_fields(dfs_c))]\n",
    "    print('Uncommon fields dropped')\n",
    "    return dfs_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_year_column(dfs_):\n",
    "    dfs_c = dfs_.copy()\n",
    "    for year in dfs_c:\n",
    "        df = dfs_c[year].copy()\n",
    "        df['race year'] = int(year)\n",
    "        dfs_c[year] = df\n",
    "    print('Year column created')\n",
    "    return dfs_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_merged_df(dfs_):\n",
    "    return pd.concat(list(dfs_.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_categories(df_):\n",
    "    \"\"\"\n",
    "    rename important categories and drop unused\n",
    "    resulting categories are split into two columns:\n",
    "        - distance\n",
    "        - gender\n",
    "    old category column is dropped\n",
    "    \"\"\"\n",
    "    df_c = df_.copy()\n",
    "    df_c['catégorie'] = df_['catégorie'].replace({\n",
    "        r'^(\\d\\d)[-/][MQS]*([DH])\\d+$' : r'\\1|\\2',\n",
    "        r'^Q([DH])\\d$' : r'10|\\1',\n",
    "        r'^S([DH])\\d$' : r'21|\\1',\n",
    "        r'^M([DH])\\d$' : r'42|\\1'\n",
    "    }, regex = True)\n",
    "    \n",
    "    # columns to keep\n",
    "    keep = [str(x) + '|H' for x in [10, 21, 42]]\n",
    "    keep.extend([str(x) + '|D' for x in [10, 21, 42]])\n",
    "    \n",
    "    # drop all other rows\n",
    "    df_c = df_c[df_c['catégorie'].isin(keep)]\n",
    "    \n",
    "    # split catégorie into two columns\n",
    "    df_c[['category', 'gender']] = df_c['catégorie'].str.split(\n",
    "        '|', expand=True\n",
    "    )\n",
    "    \n",
    "    # replace german gender abbreviations\n",
    "    df_c['gender'] = df_c['gender'].replace({\n",
    "        'H' : 'male',\n",
    "        'D' : 'female'\n",
    "    })\n",
    "    \n",
    "    df_c = df_c.drop('catégorie', axis=1)\n",
    "    \n",
    "    return df_c\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping, Parsing & Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load data from pickle\n",
      "Columns separated\n",
      "Renamed Kategorie to catégorie in year 2002\n",
      "Renamed Rang to rang in year 2002\n",
      "Renamed Name/Ort to nom/lieu in year 2002\n",
      "Renamed Jg to an in year 2002\n",
      "Renamed Team/Ortschaft to équipe/lieu in year 2002\n",
      "Renamed Zeit to temps in year 2002\n",
      "Renamed Rückstand to retard in year 2002\n",
      "Renamed Stnr to doss in year 2002\n",
      "Column names normalized\n",
      "Cities fixed\n",
      "Uncommon fields dropped\n",
      "Year column created\n"
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "rankings, headers = get_data()\n",
    "# Separate data into columns and build dataframes\n",
    "dfs = separate_cols(rankings, headers)\n",
    "# Make sure the same columns have the same column names\n",
    "dfs_n = normalize_column_names(dfs)\n",
    "# Fix cities which are in the name column in some cases\n",
    "dfs_f = fix_cities(dfs_n)\n",
    "# Drop columns that are unique to some years\n",
    "dfs_d = drop_uncommon_fields(dfs_f)\n",
    "# Create year columns\n",
    "dfs_y = create_year_column(dfs_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create final dataframe\n",
    "df = create_merged_df(dfs_y)\n",
    "# normalize categories\n",
    "df = normalize_categories(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rang</th>\n",
       "      <th>retard</th>\n",
       "      <th>lieu</th>\n",
       "      <th>an</th>\n",
       "      <th>nom</th>\n",
       "      <th>temps</th>\n",
       "      <th>doss</th>\n",
       "      <th>race year</th>\n",
       "      <th>category</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>676.</td>\n",
       "      <td>45.43,3</td>\n",
       "      <td>N-Oteren</td>\n",
       "      <td>1981</td>\n",
       "      <td>Aarskog Kay-Morten</td>\n",
       "      <td>1:15.48,7</td>\n",
       "      <td>(16798)</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>484.</td>\n",
       "      <td>53.40,3</td>\n",
       "      <td>Ecublens VD</td>\n",
       "      <td>1994</td>\n",
       "      <td>Abadie Théo</td>\n",
       "      <td>2:03.37,1</td>\n",
       "      <td>(3616)</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139.</td>\n",
       "      <td>23.51,0</td>\n",
       "      <td>St-Légier-La Chiésaz</td>\n",
       "      <td>1966</td>\n",
       "      <td>Abaidia Jilani</td>\n",
       "      <td>1:45.25,0</td>\n",
       "      <td>(4078)</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77.</td>\n",
       "      <td>30.40,6</td>\n",
       "      <td>St-Légier</td>\n",
       "      <td>1972</td>\n",
       "      <td>Abaidia Sandrine</td>\n",
       "      <td>1:53.23,1</td>\n",
       "      <td>(4076)</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>428.</td>\n",
       "      <td>23.59,5</td>\n",
       "      <td>Renens VD</td>\n",
       "      <td>1991</td>\n",
       "      <td>Abawi Khaled</td>\n",
       "      <td>53.23,8</td>\n",
       "      <td>(12280)</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rang   retard                  lieu    an                 nom      temps  \\\n",
       "0  676.  45.43,3              N-Oteren  1981  Aarskog Kay-Morten  1:15.48,7   \n",
       "1  484.  53.40,3           Ecublens VD  1994         Abadie Théo  2:03.37,1   \n",
       "2  139.  23.51,0  St-Légier-La Chiésaz  1966      Abaidia Jilani  1:45.25,0   \n",
       "3   77.  30.40,6             St-Légier  1972    Abaidia Sandrine  1:53.23,1   \n",
       "4  428.  23.59,5             Renens VD  1991        Abawi Khaled    53.23,8   \n",
       "\n",
       "      doss  race year category  gender  \n",
       "0  (16798)       2017       10    male  \n",
       "1   (3616)       2017       21    male  \n",
       "2   (4078)       2017       21    male  \n",
       "3   (4076)       2017       21  female  \n",
       "4  (12280)       2017       10    male  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print overview of columns for inspection\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read location data\n",
    "df_loc = pd.read_csv('../data/previous version/marathon-data-with-geo.csv')\n",
    "\n",
    "# get location columns to merge with data\n",
    "merge_cols = df_loc[[\n",
    "    'lieu', 'format_city', 'Canton', \n",
    "    'country', 'lat', 'lng'\n",
    "]].drop_duplicates()\n",
    "\n",
    "# merge location data into dataframe\n",
    "df_data = pd.merge(df, merge_cols, on='lieu', how='inner')\n",
    "df_data = df_data.dropna(subset=['country'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop runners with missing birth year\n",
    "df_data.drop(df_data.loc[df_data['an'] == '????'].index, axis=0,inplace=True)\n",
    "df_data.drop(df_data.loc[df_data['an'] == '??'].index, axis=0,inplace=True)\n",
    "\n",
    "# drop disqualified runners (no time / rank)\n",
    "df_data.drop(df_data.loc[df_data['temps'].str.contains('-')].index, axis=0, inplace=True)\n",
    "\n",
    "# Normalize birth years to 4 digits\n",
    "df_data['an'] = df_data['an'].astype(int)\n",
    "df_data['an'] = df_data['an'].apply(lambda x: 1900+x if x < 100 else x)\n",
    "\n",
    "# Drop unused columns\n",
    "df_data.drop(['lieu','doss','retard'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "rename_columns = {\n",
    "    'rang': 'rank',\n",
    "    'an': 'birth year',\n",
    "    'nom': 'name',\n",
    "    'temps': 'time',\n",
    "    'format_city': 'city',\n",
    "    'Canton': 'canton',\n",
    "    'country': 'country',\n",
    "    'lat': 'latitude',\n",
    "    'lng': 'longitude'\n",
    "}\n",
    "df_data.rename(columns=rename_columns, inplace=True)\n",
    "\n",
    "# Remove NaN locations\n",
    "df_data.drop(df_data[df_data['city'].isnull() == True].index, axis=0, inplace=True)\n",
    "\n",
    "# Calculate age\n",
    "df_data['age'] = df_data['race year'] - df_data['birth year']\n",
    "\n",
    "# Create age groups\n",
    "def ageGroup(x):\n",
    "    if x >= 20 and x < 30:\n",
    "        return '20-30'\n",
    "    elif x >= 30 and x < 40:\n",
    "        return '30-40'\n",
    "    elif x >= 40 and x < 50: \n",
    "        return '40-50'\n",
    "    else:\n",
    "        return 'other'\n",
    "df_data['age group'] = df_data['age'].apply(ageGroup)\n",
    "\n",
    "df_data['canton'] = df_data['canton'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_data = df_data[['name','birth year','age','age group','gender','race year','category','rank','time','city','canton','country','latitude','longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          0\n",
       "birth year    0\n",
       "age           0\n",
       "age group     0\n",
       "gender        0\n",
       "race year     0\n",
       "category      0\n",
       "rank          0\n",
       "time          0\n",
       "city          0\n",
       "canton        0\n",
       "country       0\n",
       "latitude      0\n",
       "longitude     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check NaNs\n",
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>birth year</th>\n",
       "      <th>age</th>\n",
       "      <th>age group</th>\n",
       "      <th>gender</th>\n",
       "      <th>race year</th>\n",
       "      <th>category</th>\n",
       "      <th>rank</th>\n",
       "      <th>time</th>\n",
       "      <th>city</th>\n",
       "      <th>canton</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aarskog Kay-Morten</td>\n",
       "      <td>1981</td>\n",
       "      <td>36</td>\n",
       "      <td>30-40</td>\n",
       "      <td>male</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>676.</td>\n",
       "      <td>1:15.48,7</td>\n",
       "      <td>Oteren</td>\n",
       "      <td>Troms</td>\n",
       "      <td>NO</td>\n",
       "      <td>69.255568</td>\n",
       "      <td>19.884419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haaland Arne Kristoffer</td>\n",
       "      <td>1981</td>\n",
       "      <td>36</td>\n",
       "      <td>30-40</td>\n",
       "      <td>male</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>179.</td>\n",
       "      <td>1:37.17,0</td>\n",
       "      <td>Oteren</td>\n",
       "      <td>Troms</td>\n",
       "      <td>NO</td>\n",
       "      <td>69.255568</td>\n",
       "      <td>19.884419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abadie Théo</td>\n",
       "      <td>1994</td>\n",
       "      <td>23</td>\n",
       "      <td>20-30</td>\n",
       "      <td>male</td>\n",
       "      <td>2017</td>\n",
       "      <td>21</td>\n",
       "      <td>484.</td>\n",
       "      <td>2:03.37,1</td>\n",
       "      <td>Ecublens</td>\n",
       "      <td>VD</td>\n",
       "      <td>CH</td>\n",
       "      <td>46.529636</td>\n",
       "      <td>6.561525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alves Maria</td>\n",
       "      <td>1978</td>\n",
       "      <td>39</td>\n",
       "      <td>30-40</td>\n",
       "      <td>female</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>315.</td>\n",
       "      <td>56.25,6</td>\n",
       "      <td>Ecublens</td>\n",
       "      <td>VD</td>\n",
       "      <td>CH</td>\n",
       "      <td>46.529636</td>\n",
       "      <td>6.561525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angües José</td>\n",
       "      <td>1993</td>\n",
       "      <td>24</td>\n",
       "      <td>20-30</td>\n",
       "      <td>male</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>423.</td>\n",
       "      <td>52.59,6</td>\n",
       "      <td>Ecublens</td>\n",
       "      <td>VD</td>\n",
       "      <td>CH</td>\n",
       "      <td>46.529636</td>\n",
       "      <td>6.561525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name  birth year  age age group  gender  race year  \\\n",
       "0       Aarskog Kay-Morten        1981   36     30-40    male       2017   \n",
       "1  Haaland Arne Kristoffer        1981   36     30-40    male       2017   \n",
       "2              Abadie Théo        1994   23     20-30    male       2017   \n",
       "3              Alves Maria        1978   39     30-40  female       2017   \n",
       "4              Angües José        1993   24     20-30    male       2017   \n",
       "\n",
       "  category  rank       time      city canton country   latitude  longitude  \n",
       "0       10  676.  1:15.48,7    Oteren  Troms      NO  69.255568  19.884419  \n",
       "1       21  179.  1:37.17,0    Oteren  Troms      NO  69.255568  19.884419  \n",
       "2       21  484.  2:03.37,1  Ecublens     VD      CH  46.529636   6.561525  \n",
       "3       10  315.    56.25,6  Ecublens     VD      CH  46.529636   6.561525  \n",
       "4       10  423.    52.59,6  Ecublens     VD      CH  46.529636   6.561525  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_data.to_csv('../data/marathon_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
